---
layout: post
title: Using performance counters on linux
date: '2012-12-01T11:13:00.001-08:00'
summary: Details on performance counters in linux
author: Evgeny Budilovsky
tags:
- performance
- linux
modified_time: '2012-12-01T11:13:32.213-08:00'
blogger_id: tag:blogger.com,1999:blog-3944306087401582339.post-7392806358246053539
blogger_orig_url: http://meta-x86.blogspot.com/2012/12/using-performance-counters-on-linux.html
---

One&nbsp;extremely&nbsp;useful&nbsp;feature linux has to offer is the ability to profile your system (user space and kernel) using the <a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> utility.<br /><br />In a nutshell this utility allows you to count hardware and software events in linux kernel.&nbsp;Additional&nbsp;bonus is that when you count these events you can record <a href="http://en.wikipedia.org/wiki/Instruction_pointer">cpu instruction pointer</a> at the time of the event. Instruction pointer records, later can be used to generate&nbsp;concise&nbsp;execution profile of the kernel/user space code.<br /><br />Similarly to git, perf uses sub-utils to introduce various functionality:<br /><br />The first step is to list available events:<br /><br /><div style="background: #202020; background: black; border-width: .1em .1em .1em .8em; border: solid gray; color: white; font-size: 12px; font-size: 12px; overflow: auto; padding: .2em .6em; width: auto;"><pre style="line-height: 125%; margin: 0; overflow-x: hidden; background-color: #202020; border: 0px; border-radius:0px"><span style="color: #aaaaaa;">root@dev-12:#</span> perf list<br /><br /><span style="color: #cccccc;">List of pre-defined events (to be used in -e):</span><br /><span style="color: #cccccc;">  cpu-cycles OR cycles                               [Hardware event]</span><br /><span style="color: #cccccc;">  stalled-cycles-frontend OR idle-cycles-frontend    [Hardware event]</span><br /><span style="color: #cccccc;">  stalled-cycles-backend OR idle-cycles-backend      [Hardware event]</span><br /><span style="color: #cccccc;">  instructions                                       [Hardware event]</span><br /><span style="color: #cccccc;">  cache-references                                   [Hardware event]</span><br /><span style="color: #cccccc;">  cache-misses                                       [Hardware event]</span><br /><span style="color: #cccccc;">  branch-instructions OR branches                    [Hardware event]</span><br /><span style="color: #cccccc;">  branch-misses                                      [Hardware event]</span><br /><span style="color: #cccccc;">  bus-cycles                                         [Hardware event]</span><br /><br /><span style="color: #cccccc;">  cpu-clock                                          [Software event]</span><br /><span style="color: #cccccc;">  task-clock                                         [Software event]</span><br /><span style="color: #cccccc;">  page-faults OR faults                              [Software event]</span><br /></pre></div><br />There are tons of events which we can divide into the following main categories:<br /><ul><li>Hardware events</li><li>Hardware cache events</li><li>Software events</li><li>Tracepoint events</li></ul><div>Tracepoints events are special places in kernel that were specified by developers as a good position to trace. Stopping there usually brings you to the location where some important kernel functions starts or completes.</div><div><br /></div><div>For example <i>block:block_rq_complete &nbsp;</i>trace event is passed when block i/o request completes.</div><div><br /></div><div>Hardware events make use of special cpu hardware registers, which count cpu cpecific hardware events and trigger interrupt when certain threshold is passed. Software events do not require special hardware support and usually generated by kernel handlers which process special events such as page fault.</div><div><br /></div><div>To watch statistics of events in the system you can use <i>stat</i>&nbsp;command:</div><div><br /></div><div style="background: #202020; background: black; border-width: .1em .1em .1em .8em; border: solid gray; color: white; font-size: 12px; font-size: 12px; overflow: auto; padding: .2em .6em; width: auto;"><pre style="line-height: 125%; margin: 0; overflow-x: hidden; background-color: #202020; border: 0px; border-radius:0px"><span style="color: #aaaaaa;">root@dev-12:#</span> perf stat -e syscalls:sys_enter_write,page-faults \</pre><pre style="line-height: 125%; margin: 0; overflow-x: hidden; background-color: #202020; border: 0px; border-radius:0px"><span style="color: #24909d;">                                       echo </span>hello world &gt; 1.txt<br /><br /><span style="color: #cccccc;"> Performance counter stats for 'echo hello world':</span><br /><br /><span style="color: #cccccc;">                 1 syscalls:sys_enter_write                                    </span><br /><span style="color: #cccccc;">               165 page-faults                                                 </span><br /><br /><span style="color: #cccccc;">       0.001013974 seconds time elapsed</span><br /></pre></div><br />filtering using <i>-e</i> flag is possible and it is possible to count events on existing process using <i>-p</i> flag<br /><br />Another step in using perf is to realize that events can be recorded using <i>record </i>command:<br /><br /><div style="background: #202020; background: black; border-width: .1em .1em .1em .8em; border: solid gray; color: white; font-size: 12px; overflow: auto; padding: .2em .6em; width: auto;"><pre style="line-height: 125%; margin: 0; overflow-x: hidden; background-color: #202020; border: 0px; border-radius:0px"><span style="color: #aaaaaa;">root@dev-12:#</span> perf record -f hdparm -t /dev/vda &gt; /dev/null<br /><span style="color: #cccccc;">[ perf record: Woken up 1 times to write data ]</span><br /><span style="color: #cccccc;">[ perf record: Captured and wrote 0.038 MB perf.data (~1673 samples) ]</span></pre></div><br />And later code execution profile can be created using&nbsp;<i>report&nbsp;</i>command (each time event occur the current instruction pointer is recorded as well):<br /><br /><div style="background: #202020; background: black; border-width: .1em .1em .1em .8em; border: solid gray; color: white; font-size: 12px; overflow: auto; padding: .2em .6em; width: auto;"><pre style="line-height: 125%; margin: 0; overflow-x: hidden; background-color: #202020; border: 0px; border-radius:0px"><span style="color: #aaaaaa;">root@dev-12:/home/local/a/hdparm-9.37#</span> perf report<br /><span style="color: #aaaaaa;">#</span> Events: 1K cpu-clock<br /><span style="color: #aaaaaa;">#</span><br /><span style="color: #aaaaaa;">#</span> Overhead  Command      Shared Object                                Symbol<br /><span style="color: #aaaaaa;">#</span> ........  .......  .................  ....................................<br /><span style="color: #aaaaaa;">#</span><br /><span style="color: #cccccc;">    25.80%   hdparm  [kernel.kallsyms]  [k] copy_user_generic_string</span><br /><span style="color: #cccccc;">     8.21%   hdparm  [kernel.kallsyms]  [k] blk_flush_plug_list</span><br /><span style="color: #cccccc;">     4.69%   hdparm  [kernel.kallsyms]  [k] get_page_from_freelist</span><br /><span style="color: #cccccc;">     3.62%   hdparm  [kernel.kallsyms]  [k] add_to_page_cache_locked</span><br /><span style="color: #cccccc;">     3.09%   hdparm  hdparm             [.] read_big_block</span><br /><span style="color: #cccccc;">     2.77%   hdparm  [kernel.kallsyms]  [k] _raw_spin_unlock_irqrestore</span><br /><span style="color: #cccccc;">     2.51%   hdparm  [kernel.kallsyms]  [k] kmem_cache_alloc</span><br /><span style="color: #cccccc;">     1.87%   hdparm  [kernel.kallsyms]  [k] __mem_cgroup_commit_charge</span><br /><span style="color: #cccccc;">     1.76%   hdparm  [kernel.kallsyms]  [k] file_read_actor</span><br /><span style="color: #cccccc;">     1.76%   hdparm  [kernel.kallsyms]  [k] __alloc_pages_nodemask</span><br /><span style="color: #cccccc;">     1.55%   hdparm  [kernel.kallsyms]  [k] alloc_pages_current</span><br /></pre></div><br />We can filter the kernel code and see where in our program we spend most of our time<br /><br /><div style="background: #202020; background: black; border-width: .1em .1em .1em .8em; border: solid gray; color: white; font-size: 12px; overflow: auto; padding: .2em .6em; width: auto;"><pre style="line-height: 125%; margin: 0; overflow-x: hidden; background-color: #202020; border: 0px; border-radius:0px"><span style="color: #aaaaaa;">root@dev-12:#</span> perf report -d hdparm<br /><span style="color: #aaaaaa;">#</span><br /><span style="color: #aaaaaa;">#</span> Events: 64  cpu-clock<br /><span style="color: #aaaaaa;">#</span><br /><span style="color: #aaaaaa;">#</span> Overhead  Command          Symbol<br /><span style="color: #aaaaaa;">#</span> ........  .......  ..............<br /><span style="color: #aaaaaa;">#</span><br /><span style="color: #cccccc;">    90.62%   hdparm  read_big_block</span><br /><span style="color: #cccccc;">     9.38%   hdparm  time_device</span><br /></pre></div><br />Also by default we use cpu-clock event as the point where we stop to look at our code execution. We can use different events to find out interesting things. For example what are the places in our code that cause page faults:<br /><br /><div style="background: #202020; background: black; border-width: .1em .1em .1em .8em; border: solid gray; color: white; font-size: 12px; overflow: auto; padding: .2em .6em; width: auto;"><pre style="line-height: 125%; margin: 0; overflow-x: hidden; background-color: #202020; border: 0px; border-radius:0px"><span style="color: #aaaaaa;">root@dev-12:#</span> perf record -f -e page-faults -F 100000 hdparm -t /dev/vda &gt; /dev/null<br /><span style="color: #cccccc;">[ perf record: Woken up 1 times to write data ]</span><br /><span style="color: #cccccc;">[ perf record: Captured and wrote 0.006 MB perf.data (~278 samples) ]</span><br /><span style="color: #aaaaaa;">root@dev-12:#</span> perf report<br /><span style="color: #aaaaaa;">#</span><br /><span style="color: #aaaaaa;">#</span> Events: 87  page-faults<br /><span style="color: #aaaaaa;">#</span><br /><span style="color: #aaaaaa;">#</span> Overhead  Command      Shared Object                    Symbol<br /><span style="color: #aaaaaa;">#</span> ........  .......  .................  ........................<br /><span style="color: #aaaaaa;">#</span><br /><span style="color: #cccccc;">    72.05%   hdparm  hdparm             [.] prepare_timing_buf</span><br /><span style="color: #cccccc;">    10.96%   hdparm  ld-2.15.so         [.] 0x16b0          </span><br /><span style="color: #cccccc;">     5.34%   hdparm  libc-2.15.so       [.] 0x86fc0         </span><br /><span style="color: #cccccc;">     2.53%   hdparm  [kernel.kallsyms]  [k] copy_user_generic_string</span><br /><span style="color: #cccccc;">     1.26%   hdparm  libc-2.15.so       [.] __ctype_init</span><br /><span style="color: #cccccc;">     1.26%   hdparm  libc-2.15.so       [.] _IO_vfscanf</span><br /><span style="color: #cccccc;">     1.26%   hdparm  libc-2.15.so       [.] strchrnul</span><br /><span style="color: #cccccc;">     1.26%   hdparm  libc-2.15.so       [.] mmap64</span><br /><span style="color: #cccccc;">     1.26%   hdparm  hdparm             [.] main</span><br /><span style="color: #cccccc;">     1.26%   hdparm  hdparm             [.] get_dev_geometry</span><br /><span style="color: #cccccc;">     1.26%   hdparm  [kernel.kallsyms]  [k] __strncpy_from_user</span><br /><span style="color: #cccccc;">     0.28%   hdparm  [kernel.kallsyms]  [k] __clear_user</span><br /></pre></div><br />To conclude,&nbsp;<i>perf </i>utility is&nbsp;extremely&nbsp;powerful&nbsp;tool. It provides accurate&nbsp;statistics&nbsp;with very little overhead, doesn't require recompilation and can be used to&nbsp;completely&nbsp;understand the overheads of kernel modules and user space application.<br /><br />What a nice addition to the&nbsp;arsenal&nbsp;of your favorite hacking tools :)<br /><br />
